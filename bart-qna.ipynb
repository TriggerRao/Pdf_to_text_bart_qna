{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.34.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: pickle-mixin in c:\\users\\soham\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\soham\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Initialize and load the pre-trained BART model\n",
    "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')\n",
    "\n",
    "# Save the model and tokenizer to a pickle file\n",
    "with open('bart_model.pkl', 'wb') as f:\n",
    "    pickle.dump((model, tokenizer), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bart_model_from_pickle(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        model, tokenizer = pickle.load(f)\n",
    "    return model, tokenizer\n",
    "\n",
    "def generate_answer(context, question, model, tokenizer):\n",
    "    input_text = f\"question: {question} context: {context}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    output = model.generate(**inputs)\n",
    "    answer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Bachelor of Engineering In Electronics and Communication Birla Institute of Technology & Science, Pilani (Aug 2018 - May 2022) Python | C++ Flask | OpenCV Tensorflow | PyTorch | Keras Docker | Kubernetes | Jenkins Worked on the analysis (detection of various elements and establishing relations between them) of organizational charts in documents using two different methods: OpenCV-based and object detection using YOLO (You only look once) models. Compared the two and selected the second method, and integrated it into the product. Deployed it using Kubernetes for various clients to use. Integrated LayoutLM and LayoutLMv2 training and prediction code into the product using RESTful APIs, significantly improving accuracy on various image and token classification features. Built and maintained Jenkins Pipelines for automating the  building of docker images and deployment of docker containers. Optimized various components of the product like model trainer, model manager (Tensorflow and PyTorch serving), prediction APIs etc. used for computer vision related tasks.  Conceptualized and created an Evaluation API that can take two or more models of the same category (object detection, image classification etc.) and output  different evaluation metrics helping people to select the best model for every task efficiently through a Swagger UI page. Proposed a very efficient solution, better than the existing software-based solutions, to improve the quality of HDR (High Dynamic Range) scenes using a single LDR (Low Dynamic Range) image using Deep Learning methods. The proposed solution also worked very well on low-light photos. Analyzed relevant research work and selected four methods. Implemented these methods using Tensorflow - Keras. Optimized the Reverse Camera Pipeline method (reducing the time of prediction by a factor of 5, model size by a factor of 10 and improving PSNR and SSIM values significantly). Tone mapped (using OpenCV) the HDR image to display it. Performed Linear Amplification on results of the Reverse Camera Pipeline method to improve very bright regions of the image. Compared my solution with many other software and hardware-based methods that other people in the company were working on and tested the model on various Samsung devices. Member of Technical Staff, XtractEdge, EdgeVerve Systems Limited (July 2022 - Present) Intern, Camera Systems, Samsung R&D Institute India-Bangalore (July 2021 - Dec 2021)  Work Experience  Education History Skills Satyam Kumar Implemented the research paper \\\"Vision: A Deep Learning Approach to provide walking assistance to the visually impaired\\\" using PyTorch. Implemented Object detection using YOLO and Depth estimation using monocular vision to find nearby objects and their approximate distance. Combined the output of Object detection and Depth estimation to get textual output like \\\"object X detected at Y meters\\\". The textual output is translated into different languages and can be provided to visually impaired people as audio aid. A wheal (localized swelling) is the outcome of a tuberculosis skin test. Measurement of dimensions of the wheal is essential to know the extent and intensity of infection. The project was part of CASTA (Clinical Assessment System for Tuberculosis Analysis), an app for automating the above process by precisely estimating the wheal dimensions using images captured from a smartphone. Tried Image segmentation approaches like Otsu's, Region growing, Watershed, K-mean clustering, Fuzzy C-means clustering, and their combinations to get the ROI (Region of Interest) i.e. the wheal. Compared the dimensions of ROI with dimensions that we got from hospitals (physically measured) to calculate accuracy and select the best method. Used OpenFace (open source face recognition software) to get important facial features. Implemented genetic algorithm on these features for recognition of different emotions (Anger, Surprise, Fear, etc.). Trained and validated the model using the CK+ dataset. Tested the model on a self-made dataset (20 images of each emotion) consisting of images of friends and achieved an accuracy of 80% on unmasked faces and 60% on masked faces. Fine-tuned model with pre-trained weights from Keras Applications (Transfer Learning) to fit the project's needs. Added some layers after NASNetMobile layers. Used Tensorflow-Keras to train these layers while freezing the rest of the layers (NASNetMobile layers) on the collected data (200 images each of Rock, Paper, Scissor, and Nothing). Random moves are played from the computer's side, and the trained model recognizes the player's move (OpenCV is used to get and process the images).  Created a Flask web application to play the game. Assistive Vision for Visually Impaired People Measurement of skin test wheals using Image segmentation approaches Emotion Recognition using Genetic Algorithm Rock Paper Scissor Game using Hand gesture recognition - Deep Learning Projects I was part of NIRMAAN, a NGO started by BITS Pilani students BITS Pilani in 2005 providing education and livelihood opportunities for underprivileged people. Played as  center half/ midfielder in the university field hockey team. Other Interests - Playing Basketball, Reading History and Philosophy. Volunteer Work and Interests Coursework equivalent to UT undergrad courses Courses  Mode of Course Grade  Equivalent to UT course Programming, Data Structures And Algorithms Using Python   Online by IIT Madras Elite +Silver (TOP 5% amongst 1844 students)  Marks - 83% CS 314 and CS 312 Computer Architecture Undergrad at BITS Pilani CLEAR ( Given on the basis of quizzes and assignment, final offine exam didn't happen due to Covid)  CS 429 Discreate Mathematics Undergrad at BITS Pilani CLEAR ( Given on the basis of quizzes and assignment, final offine exam didn't happen due to Covid) CS 311 Design and analysis of algorithms Online by IIT Madras Elite  Marks -69 % CS 331 Other courses Courses  Mode of Course Object Oriented Analysis and Design (Grade - Elite, Marks - 66%) Online by IIT Kharagpur Operating Systems (Grade - B)  Undergrad at BITS Pilani Pattern Recognition (Grade - A- ) Undergrad at BITS Pilani Machine Learning (Grade - B-)  Undergrad at BITS Pilani Neural Network and Fuzzy Logic (Grade - B-) Undergrad at BITS Pilani Deep Learning Specialization Coursera - deeplearning.ai (5 courses) - Online Machine Learning Coursera - Stanford - Online\"\n",
    "question = \"What is the name of the company you are working for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Satyam Kumar is a member of the XtractEdge team at EdgeVerve Systems Limited. He is also an intern at Samsung R&D Institute India-Bangalore. He has worked on a project to improve the quality of HDR (High Dynamic Range) images using Deep Learning methods.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pickle_file = 'bart_model.pkl'\n",
    "    \n",
    "    # Load the BART model and tokenizer from the pickle file\n",
    "    model, tokenizer = load_bart_model_from_pickle(pickle_file)\n",
    "\n",
    "    # Generate the answer using the loaded model and tokenizer\n",
    "    answer = generate_answer(context, question, model, tokenizer)\n",
    "    print(\"Answer:\", answer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
